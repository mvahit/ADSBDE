
linux_basic
01_what_is_linux.md
02_pwd_ls_history_cd.md
03_variables.md
04_PATH_which_types.md
05_regex.md
06_mkdir_touch_rm.md
07_cp_mv_rename.md
08_cat_more_less_head_tail.md
09_pipe.md
10_direction.md
11_sort.md
12_compression.md
13_archive_tar.md
14_find_locate.md
15_vi_nano.md
16_useradd_usermod.md
17_chown_file_ownership.md
18_chmod_file_mode.md
19_yum_package_manager.md
20_processes_and_services.md
20_processes.md

bash scripting
01_first_script.md
02_conditionals.md
03_arguments.md
04_file_operators.md
05_for_loop.md
06_while_loop.md
07_functions.md

docker
01_docker_intro.md
02_docker_cli.md
03_docker_hub_registry.md
04_run_start_stop_postgresql.md
05_remove_containers.md
06_docker_command_types.md
07_connect_container_shell.md
08_container_logs.md
09_volume.md
10_port_mapping.md
11_create_docker_file.md
12_docker_compose.md

airflow

git

maven

crontab

devops_ci/cd


hadoop-hdfs	
01_introduction_to_hadoop.md 
02_basic_hdfs_commands.md 
	
hadoop_yarn
01_introcudtion_to_yarn.md 
02_basic_yarn_commands.md 
03_yarn_resource_manager_ui.md 

hive 
01_introcudtion_to_hive.md 
02_beeline_connection.md 
03_sql_editor_connection.md 
04_basic_hiveql_queries.md 
05_hive_shell.md 
06_hive_partition_and_bucket.md 

	
sqoop 
sqoop_import_to_hdfs.md 
sqoop_import_to_hive.md 
sqoop_export_to_postgresql.md 
	
kafka
01_introduction_to_kafka.md 
02_kafka_cluster_with_docker.md 
03_kafka_console_consumer.md 
04_kafka_console_producer.md 
05_kafka_consumer_groups.md 
06_produce_to_kafka_with_python.md
07_configuration.md 

	
spark
01_introduction_to_spark.md 
02_sparks_toolset.md 
03_spark_dataframe.md 
04_ggregations.md 
05_joins.md 
06_spark_and_data_sources.md 
07_spark_sql.md 
08_spark_cluster_modes.md 
09_develop_and_submit_spark_applications.md 
10_spark_ui.md 
11_data_generator_for_streaming.md 
12_spark_streaming.md 
13_spark Machine_learning.md 
	
Exercise-1: Sort the most canceled product categories and cancellation amounts in descending order and write to disk in parquet format.
Exercise-2: Sort the most canceled products and cancellation amounts in descending order and write them to the hive table in snappy compressed orc format.
Final Project-1: Design and execute data pipeline 
Final Project-2: ML Classification
